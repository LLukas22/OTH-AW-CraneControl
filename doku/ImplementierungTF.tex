\section{Tensorflow - Python}
\subsection{Konzept}
Es wird ein Object-Detection-Model verwendet um über eine Webcam eine von sechs Gesten zu erkennen.
Die erkannte Geste wird in einem Buffer zwischengespeichert, und wenn mehrere Durchläufe das gleiche Ergebniss liefern wird ein Befehl an den Kran gesendet.

\begin{figure}[H]
    \centering
    \subfigure[Power]{\includegraphics[width=0.3\textwidth]{TensorFlow/Gestures/Power.PNG}}
    \subfigure[Up]{\includegraphics[width=0.3\textwidth]{TensorFlow/Gestures/Up.PNG}}
    \subfigure[Down]{\includegraphics[width=0.3\textwidth]{TensorFlow/Gestures/Down.PNG}}
    \subfigure[Left]{\includegraphics[width=0.3\textwidth]{TensorFlow/Gestures/Left.PNG}}
    \subfigure[Right]{\includegraphics[width=0.3\textwidth]{TensorFlow/Gestures/Right.PNG}}
    \subfigure[Toggle]{\includegraphics[width=0.3\textwidth]{TensorFlow/Gestures/Toggle.PNG}}
    \caption[Tensorflow Gesten]{Tensorflow Gesten. Bildquelle: eigene Bilder}
    \label{fig:Tensorflow Gesten}
\end{figure}
\newpage
\subsection{Tensorflow Trainer}
Um das tränieren der Modele zu erleichtern wurde eine C\# Application geschrieben, die diesen Vorgang weitgehend automatisiert.

\begin{figure}[H]
    \centering
    \subfigure{\includegraphics[width=0.9\textwidth]{TensorFlow/TensorflowTrainer.PNG}}
    \caption[Tensorflow Trainer]{Tensorflow Trainer}
    \label{fig:Tensorflow Trainer}
\end{figure}

\subsection{Tränieren eines eigene Models}

\subsubsection{Voraussetzungen:}

\begin{itemize}
    \item Git (\url{https://git-scm.com/downloads})
    \item C++ Build Tools (\url{https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=BuildTools&rel=16})
    \item Python 3.7.X or newer (\url{https://www.python.org/downloads/})
    \item LabelImg (\url{https://github.com/tzutalin/labelImg})
    \item Nvidia Gpu (optional but highly recommended)
    \begin{itemize}
    \item CUDA Version (\url{https://www.tensorflow.org/install/gpu})
    \item cuDNN Version (\url{https://developer.nvidia.com/cudnn})
    \end{itemize}
\end{itemize}
\newpage
\subsubsection{Erstellen eines Datensatzes}
Um eine Datensatz zu erzeugen müssen zunächst mit LabelImg Boxen (XML PASCAL VOC Format) um die zu Erkennenden Objekte gezogn werden.
Hierbei sind 150-250 Bilder pro Objekt ein guter Richtwert.

\subsubsection{Python Packete}
Die benötigten Pip-Packete werden durch Klicken des \textit{Install}-Buttons im TensorflowTrainer installiert. Soll die GPU-Version von Tensorflow installiert werden muss die CheckBox  \textit{GPU Acceleration} abgehackt werden.
Der  \textit{Uninstall}-Button entfernt alle installierten Packete.

\subsubsection{Settings.json}
Nach erstem öffnen und schließen des TensorflowTrainer wird eine Settings.json erzeugt.
\lstinputlisting[language=json,label={lst:Settings.json},
    numbers={none},
    caption={Settings.json}]
{CodeSamples/Tensorflow/Settings.json}
Hier können Einstellungen angepasst werden, wobei das Feld \textbf{ModelUrl} das wichtigste ist, da hier das zu verwendende Model des TF-Model-Zoo (\url{https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md}) angegeben werden kann.

\subsubsection{Downloads und Setup}
Um die Restlichen Daten herunterzuladen, müssen die drei \textit{Download}-Buttons betätigt werden. Um die Downloads zu löschen kann der \textit{Clear Cache}-Button verwendet werden.
Nun muss in Environment ein Ordner augewähl werden, in dem das Training statfinden soll. Danach muss der \textit{Build}-Button betätigt werden. Der \textit{Open}-Button öffnet den ObjectDetection-Ordner.
Um die Installation abzuschließen muss zuerst der \textit{Compile *.protoc Files}- und danach der \textit{Execute setup.py}-Button betätigt werden. Nun werden alle ObjectDetection Module installiert und die Tensorflow Tests ausgeführt.
Wenn das Testergebnis \textit{OK} ist war die Installation erfolgreich.

\subsubsection{TF Records}
Als Nächstes müssen alle Bilder mit *.Xml Dateien nach ObjectDetection/images/input kopiert werden und die in LabelImg verwendeten Label in richtiger Reihenfolgen in die Textbox eingegeben werden.
Danach die 4 Buttons von links nach Rechts betätigen. Dies erzeugt test- und train.record im ObjectDetection-Ordner und autogeneriert die Labelmap und customPipeline in ObjectDetection/training.

\subsubsection{Pipeline Config}
In der customPipeline.config können nach bedarf DataAugemntation-Optionen hinzugefügt oder entfernt werden (\url{https://stackoverflow.com/questions/44906317/what-are-possible-values-for-data-augmentation-options-in-the-tensorflow-object}).
\lstinputlisting[language=json,label={lst:Pipeline},
    numbers={none},
    caption={Pipeline},
    firstline=137,
    lastline=153]
{CodeSamples/Tensorflow/customPipeline.config}

Die wichtigsten anpassbaren Werten sind:

\begin{itemize}
    \item \textbf{Batch_Size} was die auf einmal zu verarbeitenden Bilder sind. Falls nicht genug RAM im System verfügbar ist muss die Batch_Size gesenk werden.
    \item \textbf{learning_rate_base} Geht der Loss nach einigen schritten gegen Unendlich ist die LearningRate zu hoch.
    \item \textbf{warmup_learning_rate} ähnlich wie learning_rate_base gilt aber nur für ersten warmup_steps.
\end{itemize}


\subsubsection{Training}
Das Training wird durch eine Click auf \textit{Start Training!} gestartet. Als andere Option kann man auch im ObjectDetection Ordner \textit{python model_main_tf2.py} ausführen. Tenorboard kann über einen Click auf \textit{Open Tensorboard} geöffnet werden.
Ändert der Loss sich nach einiger Zeit nicht mehr kann das Träning abgebrochen werden und das fertige Model über einen Klick auf \textit{Export Graph} nach ObjectDetection/export/normal exportiert werden und über  \textit{Test on Webcam} getestet werden.
\\
\textbf{Anmerkungen}
\begin{itemize}
    \item[1.] Falls die Gpu nicht über genug Videospeicher verfügt besteht die Option Systemspeicher als Puffer zu verwednen. Dazu müssen in \textit{object_detection/model_main_tf2.py} nach dem Tensorflow import folgende Zeilen eingefügt werden:
    \lstinputlisting[language=python,label={lst:Gpu Growth},
    numbers={none},
    caption={Gpu Growth},
    firstline=30,
    lastline=36]
{CodeSamples/Tensorflow/model_main_tf2.py}
    \item[2.] Falls der Tränings Prozess einen Evaluations Durchgang ausführt und der TensorflowTrainer versucht den Prozess zu schließen läuft der Pyton Prozess weiter im Hintergrund -> Schließen über TaskManager.

\end{itemize}

\subsubsection{Lite Graph}
Mit einem Klick auf \textit{Export Lite Convertible Graph} wird ein Saved Model nach ObjectDetection/export/LiteConvertibleGraph exportiert, das mit dem TFLite-Converter (\url{https://www.tensorflow.org/lite/convert}) zu einem TFLite Model convertiert werden kann.

\subsection{Python Anwendung}

\textbf{Für PI:} \\
TFLight : \url{https://www.tensorflow.org/lite/guide/python}\\
Apt.Get : sudo apt-get install python3-pil python3-pil.imagetk libatlas-base-dev libhdf5-dev libhdf5-serial-dev libatlas-base-dev libjasper-dev libqtgui4 libqt4-test\\
Pip3: pip3 install Pillow,opencv-python\\